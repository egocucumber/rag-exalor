import os
from typing import TypedDict, List
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langchain_core.messages import SystemMessage, HumanMessage
from langgraph.graph import StateGraph, END
from .database import get_vectorstore

load_dotenv()

llm = ChatGroq(model="llama-3.3-70b-versatile", temperature=0)

class GraphState(TypedDict):
    question: str
    generation: str
    documents: List[str] 

def retrieve(state):
    """–ò—â–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –±–∞–∑–µ"""
    print("--- RETRIEVE ---")
    vectorstore = get_vectorstore()
    retriever = vectorstore.as_retriever(
    search_type="mmr", 
    search_kwargs={"k": 5, "fetch_k": 20}
    )
    docs = retriever.invoke(state["question"])
    return {"documents": docs, "question": state["question"]}

def generate(state):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º"""
    print("--- GENERATE ---")
    question = state["question"]
    docs = state["documents"]
    
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs)}")
    for i, doc in enumerate(docs):
        print(f"üìÑ Doc {i+1}: {doc.page_content[:150]}...\n")    
    context = "\n\n".join([doc.page_content for doc in docs])
    
    prompt = f"""
    –¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.
    –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞, —Å–∫–∞–∂–∏ "–Ø –Ω–µ –Ω–∞—à–µ–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö".
    
    –ö–û–ù–¢–ï–ö–°–¢:
    {context}
    
    –í–û–ü–†–û–°: {question}
    """
    
    msg = [HumanMessage(content=prompt)]
    response = llm.invoke(msg)
    return {"generation": response.content}

def create_rag_graph():
    workflow = StateGraph(GraphState)
    
    workflow.add_node("retrieve", retrieve)
    workflow.add_node("generate", generate)
    
    workflow.set_entry_point("retrieve")
    workflow.add_edge("retrieve", "generate")
    workflow.add_edge("generate", END)
    
    return workflow.compile()